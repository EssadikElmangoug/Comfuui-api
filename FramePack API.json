{
  "12": {
    "inputs": {
      "vae_name": "hunyuan_video_vae_bf16.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "13": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "llava_llama3_fp16.safetensors",
      "type": "hunyuan_video",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "15": {
    "inputs": {
      "conditioning": [
        "47",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "17": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "18",
        0
      ],
      "image": [
        "48",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "18": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "19": {
    "inputs": {
      "image": "ComfyUI_00001_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image: Start"
    }
  },
  "20": {
    "inputs": {
      "pixels": [
        "48",
        0
      ],
      "vae": [
        "12",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "23": {
    "inputs": {
      "frame_rate": 30,
      "loop_count": 0,
      "filename_prefix": "FramePack",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": false,
      "images": [
        "44",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢"
    }
  },
  "27": {
    "inputs": {
      "backend": "inductor",
      "fullgraph": false,
      "mode": "default",
      "dynamic": false,
      "dynamo_cache_size_limit": 64,
      "compile_single_blocks": true,
      "compile_double_blocks": true
    },
    "class_type": "FramePackTorchCompileSettings",
    "_meta": {
      "title": "Torch Compile Settings"
    }
  },
  "33": {
    "inputs": {
      "tile_size": 256,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": [
        "39",
        0
      ],
      "vae": [
        "12",
        0
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "39": {
    "inputs": {
      "steps": 30,
      "use_teacache": true,
      "teacache_rel_l1_thresh": 0.15,
      "cfg": 1,
      "guidance_scale": 10,
      "shift": 0,
      "seed": 47,
      "latent_window_size": 9,
      "total_second_length": 5,
      "gpu_memory_preservation": 6,
      "sampler": "unipc_bh1",
      "embed_interpolation": "weighted_average",
      "start_embed_strength": 0.5,
      "denoise_strength": 1,
      "model": [
        "52",
        0
      ],
      "positive": [
        "47",
        0
      ],
      "negative": [
        "15",
        0
      ],
      "start_latent": [
        "20",
        0
      ],
      "image_embeds": [
        "17",
        0
      ],
      "end_latent": [
        "62",
        0
      ],
      "end_image_embeds": [
        "57",
        0
      ]
    },
    "class_type": "FramePackSampler",
    "_meta": {
      "title": "FramePackSampler"
    }
  },
  "44": {
    "inputs": {
      "image": [
        "33",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "47": {
    "inputs": {
      "text": "A cute anime girl with big fluffy fennec ears, a long fluffy tail, messy blonde hair, and blue eyes, wearing a black maid dress with gold leaf patterns and a white apron. She smiles with her mouth slightly open as she gently places a fancy black forest cake with lit candles onto a large dinner table. The room is a dark, old Victorian mansion lit by candles, with expensive furniture, paintings on the walls, and a bright window showing a foggy forest outside. Her ears and tail move softly as she serves the cake.",
      "clip": [
        "13",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "48": {
    "inputs": {
      "image": [
        "50",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "50": {
    "inputs": {
      "width": [
        "51",
        0
      ],
      "height": [
        "51",
        1
      ],
      "interpolation": "lanczos",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "19",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "51": {
    "inputs": {
      "base_resolution": 640,
      "image": [
        "19",
        0
      ]
    },
    "class_type": "FramePackFindNearestBucket",
    "_meta": {
      "title": "Find Nearest Bucket"
    }
  },
  "52": {
    "inputs": {
      "model": "FramePackI2V_HY_fp8_e4m3fn.safetensors",
      "base_precision": "bf16",
      "quantization": "fp8_e4m3fn",
      "load_device": "offload_device",
      "attention_mode": "sdpa"
    },
    "class_type": "LoadFramePackModel",
    "_meta": {
      "title": "Load FramePackModel"
    }
  },
  "57": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "18",
        0
      ],
      "image": [
        "60",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "58": {
    "inputs": {
      "image": "ComfyUI_00005_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image: End"
    }
  },
  "59": {
    "inputs": {
      "width": [
        "51",
        0
      ],
      "height": [
        "51",
        1
      ],
      "interpolation": "lanczos",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "58",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "60": {
    "inputs": {
      "image": [
        "59",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "62": {
    "inputs": {
      "pixels": [
        "60",
        0
      ],
      "vae": [
        "12",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  }
}